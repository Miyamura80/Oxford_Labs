{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qBOS0ukjxIQ"
      },
      "source": [
        "# Introduction\n",
        "Welcome to Practical 3 for Graph Representation Learning (MT22).  In this practical, you are expected to first implement two functions from scratch: **Graph Mini-Batching** and **Global Pooling**. Then, you need to incorporate these two functions into a graph neural network model to solve a **Graph Classification** task. \n",
        "\n",
        "- **Graph Mini-Batching** A mini-batch groups a set of graphs into a unified representation where it can efficiently be processed in parallel.\n",
        "- **Global Pooling** Obtain the graph feature based on all node features in the graph, in which you can use different operations such as summation, mean and max.\n",
        "\n",
        "We will be using [PyTorch](https://pytorch.org/docs/stable/index.html) and [PyG](https://pytorch-geometric.readthedocs.io/en/latest/) for experiments.\n",
        "\n",
        "The notebook is divided into sections, each of which comes with complete or partially completed code. Before each snippet of code there will be a description of what we are about to implement. The sections of code you need to complete are marked as **Tasks**.\n",
        "\n",
        "Please ensure that you operate within the framework given in the notebook and bring any questions you may have to the practical demonstrators. We suggest that you **DO NOT** edit code that is a part of the framework, since this will make it more difficult for demonstrators to assist if your code is broken.\n",
        "\n",
        "Since we are working in a Jupyter Notebook, the code is very interactive. When you're stuck on something, try adding a new block of code below what you're working on and using it to debug your code."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing dependencies\n",
        "First of all, we advise you to enable GPU acceleration for your notebook. This can be done by navigating to `Runtime > Change runtime type > Hardware accelerator (GPU) > Save`. You may getting an error explaining that no GPUs are currently available. This is fine, you don't really need them for this practical, however they'll make your computations significantly faster.\n",
        "\n",
        "Some other tips & tricks:\n",
        "- press `Shift + Enter` to run a cell and move to the next one (`Ctrl + Enter` to only run it)\n",
        "- when you execute a cell, the variables you create are saved into a global namespace. As a consequence, changes in the code will not take effect until you re-run that specific cell.\n",
        "- remember to save your notebook every once in a while!"
      ],
      "metadata": {
        "id": "pWwo4htCSNj4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNLRlgXzoJdZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d38367-c046-4af2-e125-acec88730833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n"
          ]
        }
      ],
      "source": [
        "# Check PyTorch version installed on this system\n",
        "!python -c \"import torch; print(torch.__version__)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOALkyBjnFbj"
      },
      "outputs": [],
      "source": [
        "# Download the corresponding PyTorch Geometric module\n",
        "\"\"\"\n",
        "Assign to TORCH with what you get from the cell above, E.g., export TORCH=1.13.1+cu113\n",
        "\"\"\"\n",
        "%env TORCH=1.12.1+cu113\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n",
        "\n",
        "Run the following blocks of code to install and import and the necessary python packages."
      ],
      "metadata": {
        "id": "vkz6VLjOryE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's first import all the things we are gonna need for this task\n",
        "import torch\n",
        "import time \n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random \n",
        "import torch.nn.functional as F\n",
        "from torch_scatter import scatter\n",
        "from torch_geometric.nn import MessagePassing\n",
        "import torch_geometric.utils as U\n",
        "# torch_geometric only used to load the Cora dataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data.data import Data \n",
        "import torch_geometric.utils as U\n",
        "import torch\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch_geometric.datasets import TUDataset"
      ],
      "metadata": {
        "id": "wY3B_uB3ry43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Dataset\n",
        "\n",
        "## Loading MUTAG from TUDataset\n",
        "We will use TUDataset to load the MUTAG dataset, which contains molecular graphs of 188 chemical compounds divided into two classes according to their mutagenic effect on a bacterium.\n",
        "\n",
        "We construct three lists: A, X, Y, which correspond to a list of adj_matrix, a list of node features and a list of graph labels, respectively.\n",
        "\n",
        "Please **DO NOT** modify any part of the following block."
      ],
      "metadata": {
        "id": "7ZKndO0hYiKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# please **DO NOT** modify  any part of the following code  in this cell \n",
        "raw_dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
        "batch_size = 32\n",
        "A = []\n",
        "X = []\n",
        "Y = []\n",
        "for graph in raw_dataset:\n",
        "    adj_matrix = U.to_dense_adj(graph.edge_index).squeeze(0)\n",
        "    A.append(adj_matrix)\n",
        "    X.append(graph.x)\n",
        "    Y.append(graph.y)"
      ],
      "metadata": {
        "id": "xCTdKEvIobt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then run the following cell to output the first one element in the three constructed lists."
      ],
      "metadata": {
        "id": "bhI8VnJCvOf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(A[0])\n",
        "print(X[0])\n",
        "print(Y[0])"
      ],
      "metadata": {
        "id": "VjKHlRk2tbxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1\n",
        "Define an iterator `graph_mini_batch` that takes in a list of adj_matrix (A), a list of node features (X), a list of graph labels (Y) and a batch_size B=64, and outputs four items $A_B$, $X_B$, $Y_B$ and $Batch$ each time, such that the batched Adjacency matrices  $A_B$ are stacked in a diagonal fashion (creating a giant graph that holds multiple isolated subgraphs), and the batched node features list $X_B$ and the batched graph label list $Y_B$ are simply concatenated in the node dimension, i.e.,\n",
        "\n",
        "\\begin{split}\\mathbf{A_B} = \\begin{bmatrix} \\mathbf{A}_1 & & \\\\ & \\ddots & \\\\ & & \\mathbf{A}_n \\end{bmatrix}, \\qquad \\mathbf{X_B} = \\begin{bmatrix} \\mathbf{X}_1 \\\\ \\vdots \\\\ \\mathbf{X}_n \\end{bmatrix}, \\qquad \\mathbf{Y_B} = \\begin{bmatrix} \\mathbf{Y}_1 \\\\ \\vdots \\\\ \\mathbf{Y}_n \\end{bmatrix}.\\end{split}\n",
        "\n",
        "Furthermore, you are expected to output a  **`Batch` vector**, which maps each node to its respective graph in the batch:\n",
        "\n",
        "$$\n",
        "\\textrm{Batch} = [ 0, \\ldots, 0, 1, \\ldots, 1, 2, \\ldots, n, \\ldots, n]\n",
        "$$\n",
        "\n",
        "**Hints:**\n",
        "1. use the keyword **yield** to make your function be an iterator.\n",
        "2. note that the last batch might not have the enough items satisfying the specified batch size, so your function should be able to deal with such a case and have a correct output."
      ],
      "metadata": {
        "id": "UlV9O3MORCTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_mini_batch(adj_matrix_list,  x_list,  y_list, batch_size=64):\n",
        "     # Implement the function here"
      ],
      "metadata": {
        "id": "54KkQeG8wL73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your batch function here \n",
        "for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, batch_size):\n",
        "     print(adj_matrix.size())\n",
        "     print(x.size())\n",
        "     print(y.size())\n",
        "     print(batch.size())"
      ],
      "metadata": {
        "id": "dpZQz5Q-zBek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2\n",
        "Define a function `global_sum_pool` which takes a batch of node features and a Batch vector mapping each node to its respective graph in the batch, and outputs a batch of graph representation vectors by summing all node features in a graph.\n",
        "\n",
        "**Hints:** You are allowed to use the function scatter from torch_scatter library. See [here](https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html#torch_scatter.scatter) for a detailed introduction about the usage. "
      ],
      "metadata": {
        "id": "w7k4UptPbCf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "# SOLUTION\n",
        "###\n",
        "\n",
        "def global_sum_pool(x, batch):\n",
        "   # Implement the function here\n"
      ],
      "metadata": {
        "id": "i6YFBsNrbdZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your pooling function, assuming you are given a mini-batch of node features and a batch vector\n",
        "for _, x, _ , batch in graph_mini_batch(A, X, Y, batch_size):\n",
        "      sum_graph_rep =  global_sum_pool(x, batch)\n",
        "      print(sum_graph_rep.size())"
      ],
      "metadata": {
        "id": "ABuRS36DVn5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "We now implement a GNN model, `GIN`, which is used to do the graph classification. **DO NOT** change the following block. "
      ],
      "metadata": {
        "id": "c_BV3iHA9Gaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GINConv(MessagePassing):\n",
        "    def __init__(self, emb_dim):\n",
        "        '''\n",
        "            emb_dim (int): node embedding dimensionality\n",
        "        '''\n",
        "        super(GINConv, self).__init__(aggr = \"add\")\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(torch.nn.Linear(emb_dim, 2*emb_dim), torch.nn.BatchNorm1d(2*emb_dim), torch.nn.ReLU(), torch.nn.Linear(2*emb_dim, emb_dim))\n",
        "        self.eps = torch.nn.Parameter(torch.Tensor([0]))\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        out = self.mlp((1 + self.eps) *x + self.propagate(edge_index, x=x))\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j):\n",
        "        return F.relu(x_j)\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        return aggr_out\n",
        "\n",
        "\n",
        "### GNN to generate node embedding\n",
        "class GIN(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Output:\n",
        "        node representations\n",
        "    \"\"\"\n",
        "    def __init__(self, num_layer, emb_dim, hidden_dim, drop_ratio = 0, JK = \"last\", residual = False):\n",
        "        '''\n",
        "            emb_dim (int): node embedding dimensionality\n",
        "            num_layer (int): number of GNN message passing layers\n",
        "        '''\n",
        "        super(GIN, self).__init__()\n",
        "        self.num_layer = num_layer\n",
        "        self.drop_ratio = drop_ratio\n",
        "        self.JK = JK\n",
        "        ### add residual connection or not\n",
        "        self.residual = residual\n",
        "        if self.num_layer < 2:\n",
        "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
        "\n",
        "        self.embed = torch.nn.Linear(emb_dim, hidden_dim)\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.batch_norms = torch.nn.ModuleList()\n",
        "        for layer in range(num_layer):\n",
        "            self.convs.append(GINConv(hidden_dim))\n",
        "            self.batch_norms.append(torch.nn.BatchNorm1d(hidden_dim))\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        h_list = [self.embed(x)]\n",
        "        for layer in range(self.num_layer):\n",
        "            h = self.convs[layer](h_list[layer], edge_index)\n",
        "            h = self.batch_norms[layer](h)\n",
        "            if layer == self.num_layer - 1:\n",
        "                #remove relu for the last layer\n",
        "                h = F.dropout(h, self.drop_ratio, training = self.training)\n",
        "            else:\n",
        "                h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n",
        "\n",
        "            if self.residual:\n",
        "                h += h_list[layer]\n",
        "\n",
        "            h_list.append(h)\n",
        "        ### Different implementations of Jk-concat\n",
        "        if self.JK == \"last\":\n",
        "            node_representation = h_list[-1]\n",
        "        elif self.JK == \"sum\":\n",
        "            node_representation = 0\n",
        "            for layer in range(self.num_layer + 1):\n",
        "                node_representation += h_list[layer]\n",
        "\n",
        "        return node_representation"
      ],
      "metadata": {
        "id": "UUQGCU9-YQVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the hyperparameters we are going to use"
      ],
      "metadata": {
        "id": "wIrzU7d_-K1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"input_features\": 7,\n",
        "    \"hidden_features\": 50,\n",
        "    \"num_layers\": 3,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"weight_decay\": 0,\n",
        "    \"num_epochs\": 100,\n",
        "    \"num_classes\": 2,\n",
        "    \"batch_size\": 32\n",
        "}\n"
      ],
      "metadata": {
        "id": "uATxaDKL-QzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we come to the most exciting part, that is, training and evaluating the model based on the graph mini-batch and the graph pooling functions you implemented above. \n",
        "\n",
        "By checking the training time,  you can see the power of the graph batching by changing the batch_size, i.e., from 1 to 64. "
      ],
      "metadata": {
        "id": "sX7kDGkY-jdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "begin_time = time.time()\n",
        "\n",
        "model = GIN(params[\"num_layers\"], params[\"input_features\"], params[\"hidden_features\"])\n",
        "pooling = global_sum_pool\n",
        "graph_pred_linear = torch.nn.Linear(params[\"hidden_features\"], params[\"num_classes\"])\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "model_param_group = [{\"params\": model.parameters(), \"lr\": params[\"learning_rate\"]}]\n",
        "if graph_pred_linear is not None:\n",
        "        model_param_group.append(\n",
        "            {\"params\": graph_pred_linear.parameters(), \"lr\": params[\"learning_rate\"]}\n",
        "        )\n",
        "\n",
        "optimizer = torch.optim.AdamW(model_param_group,\n",
        "                                lr=params[\"learning_rate\"],\n",
        "                                weight_decay=params[\"weight_decay\"])\n",
        "for epoch in range(params[\"num_epochs\"]):\n",
        "  model.train()\n",
        "  for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
        "      optimizer.zero_grad()\n",
        "      edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
        "      nodes = model(x, edge_index)\n",
        "      graph_reps = pooling(nodes, batch)\n",
        "      pred = graph_pred_linear(graph_reps)\n",
        "      loss = loss_fn(pred, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "  if epoch % 10 == 0:\n",
        "      model.eval()\n",
        "      correct = 0\n",
        "      total_num = 0 \n",
        "      for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
        "        optimizer.zero_grad()\n",
        "        edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
        "        nodes = model(x, edge_index)\n",
        "        graph_reps = pooling(nodes, batch)\n",
        "        pred = graph_pred_linear(graph_reps)\n",
        "        correct += (pred.argmax(dim=-1) == y).sum()\n",
        "        total_num += len(y)\n",
        "      print(\"epoch={}, loss={}, accuracy={}\".format(epoch, loss.item(), correct/total_num))\n",
        "print(\"time={}\".format(time.time()-begin_time))"
      ],
      "metadata": {
        "id": "64Mw0rgPeiEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3 (Optional)\n",
        "This is an optional task. You are expected to implement 10-Fold Cross-validation. The general procedure is as follows:\n",
        "\n",
        "1. Shuffle the dataset randomly.\n",
        "2. Split the dataset into k groups. \n",
        "For each unique group:\n",
        "  - Take the group as a hold out or test data set\n",
        "  - Take the remaining groups as a training data set\n",
        "  - Fit a model on the training set and evaluate it on the test set.\n",
        "  Retain the evaluation score and discard the model\n",
        "  - Summarize the skill of the model using the sample of model evaluation scores"
      ],
      "metadata": {
        "id": "ieNyeHvcVR9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implement your  solutions here "
      ],
      "metadata": {
        "id": "VeZtBHmhhtX4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}